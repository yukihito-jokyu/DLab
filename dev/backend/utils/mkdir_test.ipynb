{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'successfully'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ユーザーのディレクトリを作成する関数\n",
    "def create_user_directory(data):\n",
    "\n",
    "    user_id = data[\"user_id\"]\n",
    "\n",
    "    base_path = \"../user\"\n",
    "    user_path = os.path.join(base_path, user_id)\n",
    "    \n",
    "    # ユーザーディレクトリを作成（すでに存在する場合は何もしない）\n",
    "    try:\n",
    "        os.makedirs(user_path, exist_ok=True)\n",
    "        os.makedirs(os.path.join(user_path, \"CartPole\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(user_path, \"FlappyBird\"), exist_ok=True)\n",
    "        return {\"message\": \"successfully\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\": str(e)}\n",
    "\n",
    "# 使用例\n",
    "data = {\n",
    "    \"user_id\": \"example_user_id\"\n",
    "}\n",
    "\n",
    "response = create_user_directory(data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'successfully'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# プロジェクトディレクトリを作成する関数\n",
    "def create_project_directory(data):\n",
    "\n",
    "    user_id = data[\"user_id\"]\n",
    "    project_name = data[\"project_name\"]\n",
    "\n",
    "    base_path = \"../user\"\n",
    "    user_path = os.path.join(base_path, user_id)\n",
    "    project_path = os.path.join(user_path, project_name)\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(project_path, exist_ok=True)\n",
    "        return {\"message\": \"successfully\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\": str(e)}\n",
    "\n",
    "# 使用例\n",
    "data = {\n",
    "    \"user_id\": \"example_user_id\",\n",
    "    \"project_name\": \"example_project\"\n",
    "}\n",
    "response = create_project_directory(data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'successfully'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_model_directory_from_dict(data):\n",
    "\n",
    "    user_id = data[\"user_id\"]\n",
    "    project_name = data[\"project_name\"]\n",
    "    model_id = data[\"model_id\"]\n",
    "\n",
    "    base_path = \"../user\"\n",
    "    project_path = os.path.join(base_path, user_id, project_name)\n",
    "    model_path = os.path.join(project_path, model_id)\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        return {\"message\": \"successfully\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\": str(e)}\n",
    "\n",
    "# 使用例\n",
    "data = {\n",
    "    \"user_id\": \"example_user_id\",\n",
    "    \"project_name\": \"example_project\",\n",
    "    \"model_id\": \"example_model\"\n",
    "}\n",
    "response = create_model_directory_from_dict(data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'successfully'}\n"
     ]
    }
   ],
   "source": [
    "def make_conv_layer(layer):\n",
    "    return f'            nn.Conv2d({layer[\"in_channels\"]}, {layer[\"out_channel\"]}, {layer[\"kernel_size\"]}, stride={layer[\"stride\"]}, padding={layer[\"padding\"]}),\\n'\n",
    "\n",
    "def make_pool_layer(pool_type, kernel_size, stride, padding):\n",
    "    return f'            nn.{pool_type}({kernel_size}, stride={stride}, padding={padding}),\\n'\n",
    "\n",
    "def make_dropout_layer(dropout_p):\n",
    "    return f'            nn.Dropout(p={dropout_p}),\\n'\n",
    "\n",
    "def make_batchnorm_layer(num_features):\n",
    "    return f'            nn.BatchNorm2d({num_features}),\\n'\n",
    "\n",
    "def make_linear(input_size, output_size):\n",
    "    return f'            nn.Linear({input_size}, {output_size}),\\n'\n",
    "\n",
    "def make_activ(activ_name):\n",
    "    return f'            nn.{activ_name}(),\\n'\n",
    "\n",
    "def make_flatten_bif(flutten_bif):\n",
    "    return f'            nn.{flutten_bif}(1),\\n'\n",
    "\n",
    "def make_python_code(data):\n",
    "    py_1 = '''\n",
    "import torch.nn as nn\n",
    "'''\n",
    "    py_2 = '''\n",
    "class Simple_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple_NN, self).__init__()\n",
    "'''\n",
    "    py_3 = '''\n",
    "        self.seq = nn.Sequential(\n",
    "'''\n",
    "    py_4 = '''\n",
    "            )\n",
    "'''\n",
    "    py_5 = '''\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "'''\n",
    "    structure = data.get('structure')\n",
    "    input_layer = structure.get('InputLayer')\n",
    "    conv_layers = structure.get('ConvLayer')\n",
    "    middle_layers = structure.get('MiddleLayer')\n",
    "    output_size = structure.get('OutputLayer')\n",
    "    flutten_way = structure.get('Flatten_way')\n",
    "    save_dir = f'../user/{data.get(\"user_id\")}/{data.get(\"Project_name\")}/{data.get(\"model_id\")}'\n",
    "\n",
    "    in_channels = input_layer[2]\n",
    "    for layer in conv_layers:\n",
    "        layer_type = layer.get('layer_type')\n",
    "        if layer_type == 'conv2d':\n",
    "            py_3 += make_conv_layer(layer)\n",
    "            py_3 += make_activ(layer.get('activ_func'))\n",
    "            in_channels = layer.get('out_channel')\n",
    "        elif layer_type == 'pool':\n",
    "            py_3 += make_pool_layer(layer.get('pool_type'), layer.get('kernel_size'), layer.get('stride'), layer.get('padding'))\n",
    "        elif layer_type == 'dropout':\n",
    "            py_3 += make_dropout_layer(layer.get('dropout_p'))\n",
    "        elif layer_type == 'batchnorm':\n",
    "            py_3 += make_batchnorm_layer(in_channels)\n",
    "\n",
    "    if flutten_way == 'GAP':\n",
    "        py_3 += '            nn.AdaptiveAvgPool2d(1),\\n'\n",
    "    elif flutten_way == 'GMP':\n",
    "        py_3 += '            nn.AdaptiveMaxPool2d(1),\\n'\n",
    "\n",
    "    py_3 += '            nn.Flatten(),\\n'\n",
    "\n",
    "    input_size = in_channels\n",
    "\n",
    "    for layer in middle_layers:\n",
    "        py_3 += make_linear(input_size, layer.get('input_size'))\n",
    "        py_3 += make_activ(layer.get('activ_func'))\n",
    "        input_size = layer.get('input_size')\n",
    "\n",
    "    py_3 += make_linear(input_size, output_size)\n",
    "\n",
    "    python_code = py_1 + py_2 + py_3 + py_4 + py_5\n",
    "    file_name = 'model_config.py'\n",
    "\n",
    "    try:\n",
    "        with open(f\"{save_dir}/{file_name}\", 'w') as file:\n",
    "            file.write(python_code)\n",
    "        return {\"message\": \"successfully\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\": str(e)}\n",
    "\n",
    "# 使用例\n",
    "data = {\n",
    "    \"model_type\": \"Conv\",\n",
    "    \"user_id\": \"example_user_id\",\n",
    "    \"Project_name\": \"example_project\",\n",
    "    \"model_id\": \"example_model\",\n",
    "    \"structure\": {\n",
    "        \"InputLayer\": [28, 28, 1],\n",
    "        \"Pretreatment\": \"none\",\n",
    "        \"ConvLayer\": [\n",
    "            {\n",
    "                \"layer_type\": \"conv2d\",\n",
    "                \"in_channels\": 1,\n",
    "                \"out_channel\": 64,\n",
    "                \"kernel_size\": 3,\n",
    "                \"stride\": 1,\n",
    "                \"padding\": 0,\n",
    "                \"activ_func\": \"ReLU\"\n",
    "            },\n",
    "            {\n",
    "                \"layer_type\": \"padding\",\n",
    "                \"kernel_size\": 3,\n",
    "                \"stride\": 1,\n",
    "                \"padding\": 0\n",
    "            },\n",
    "            {\n",
    "                \"layer_type\": \"dropout\",\n",
    "                \"dropout_p\": 0.2\n",
    "            },\n",
    "            {\n",
    "                \"layer_type\": \"batchnorm\"\n",
    "            }\n",
    "        ],\n",
    "        \"Flatten_way\": \"GMP\",\n",
    "        \"MiddleLayer\": [\n",
    "            {\n",
    "                \"input_size\": 100,\n",
    "                \"activ_func\": \"Tanh\"\n",
    "            },\n",
    "            {\n",
    "                \"input_size\": 100,\n",
    "                \"activ_func\": \"Sigmoid\"\n",
    "            }\n",
    "        ],\n",
    "        \"OutputLayer\": 10\n",
    "    }\n",
    "}\n",
    "response = make_python_code(data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Failed to delete some directories'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def delete_model_directories(data):\n",
    "    user_id = data[\"user_id\"]\n",
    "    project_name = data[\"Project_name\"]\n",
    "    model_id_list = data[\"model_id_list\"]\n",
    "\n",
    "    base_path = \"../user\"\n",
    "    project_path = os.path.join(base_path, user_id, project_name)\n",
    "    \n",
    "    all_deleted = True\n",
    "    \n",
    "    try:\n",
    "        for model_id in model_id_list:\n",
    "            model_path = os.path.join(project_path, model_id)\n",
    "            if os.path.exists(model_path):\n",
    "                shutil.rmtree(model_path)\n",
    "            else:\n",
    "                all_deleted = False\n",
    "        if all_deleted:\n",
    "            return {\"message\": \"successfully\"}\n",
    "        else:\n",
    "            return {\"message\": \"Failed\"}\n",
    "    except Exception as e:\n",
    "        return {\"message\": str(e)}\n",
    "\n",
    "# 使用例\n",
    "data = {\n",
    "    \"user_id\": \"example_user_id\",\n",
    "    \"Project_name\": \"example_project_name\",\n",
    "    \"model_id_list\": [\"example_model_id_1\", \"example_model_id_2\"]\n",
    "}\n",
    "\n",
    "response = delete_model_directories(data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iriku\\Downloads\\model_20240719_213522.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# 指定したモデルディレクトリをダウンロードする関数\n",
    "def download_model_directories(data):\n",
    "    user_id = data[\"user_id\"]\n",
    "    project_name = data[\"Project_name\"]\n",
    "    model_id_list = data[\"model_id_list\"]\n",
    "\n",
    "    base_path = \"../user\"\n",
    "    user_path = os.path.join(base_path, user_id)\n",
    "    project_path = os.path.join(user_path, project_name)\n",
    "    \n",
    "    zip_file_paths = []\n",
    "    \n",
    "    try:\n",
    "        # 各モデルのディレクトリを処理\n",
    "        for model_id in model_id_list:\n",
    "            model_path = os.path.join(project_path, model_id)\n",
    "            \n",
    "            # __pycache__ を削除\n",
    "            pycache_path = os.path.join(model_path, '__pycache__')\n",
    "            if os.path.exists(pycache_path):\n",
    "                shutil.rmtree(pycache_path)\n",
    "            \n",
    "            # モデルのディレクトリをZIPファイルに圧縮\n",
    "            zip_file_path = os.path.join(project_path, f\"{model_id}.zip\")\n",
    "            shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', model_path)\n",
    "            zip_file_paths.append(zip_file_path)\n",
    "        \n",
    "        # ユーザーのダウンロードフォルダのパスを取得\n",
    "        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "        \n",
    "        # 日付と時間を取得し＆ファイル名を生成\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        final_zip_file_name = f\"model_{current_time}.zip\"\n",
    "        final_zip_file = os.path.join(downloads_folder, final_zip_file_name)\n",
    "        \n",
    "        # すべてのZIPファイルを1つのZIPファイルに集約\n",
    "        with zipfile.ZipFile(final_zip_file, 'w') as zipf:\n",
    "            for file in zip_file_paths:\n",
    "                zipf.write(file, os.path.basename(file))\n",
    "                os.remove(file)\n",
    "\n",
    "        return final_zip_file\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# 使用例\n",
    "data = {\n",
    "    \"user_id\": \"example_user_id\",\n",
    "    \"Project_name\": \"example_project\",\n",
    "    \"model_id_list\": [\"example_model_id_1\", \"example_model_id_2\"]\n",
    "}\n",
    "\n",
    "result = download_model_directories(data)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from train.train_image_classification import GCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZCA白色化の実装\n",
    "class ZCAWhitening():\n",
    "    def __init__(self, epsilon=1e-4, device=\"cuda\"):  # 計算が重いのでGPUを用いる\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        self.mean = None\n",
    "        self.ZCA_matrix = None\n",
    "\n",
    "    def fit(self, images):  # 変換行列と平均をデータから計算\n",
    "        \"\"\"\n",
    "        Argument\n",
    "        --------\n",
    "        images : torchvision.datasets.cifar.CIFAR10\n",
    "            入力画像（訓練データ全体）．(N, C, H, W)\n",
    "        \"\"\"\n",
    "        x = images[0][0].reshape(1, -1)  # 画像（1枚）を1次元化\n",
    "        self.mean = torch.zeros([1, x.size()[1]]).to(self.device)  # 平均値を格納するテンソル．xと同じ形状\n",
    "        con_matrix = torch.zeros([x.size()[1], x.size()[1]]).to(self.device)\n",
    "        for i in range(len(images)):  # 各データについての平均を取る\n",
    "            x = images[i][0].reshape(1, -1).to(self.device)\n",
    "            self.mean += x / len(images)\n",
    "            con_matrix += torch.mm(x.t(), x) / len(images)\n",
    "            if i % 10000 == 0:\n",
    "                print(\"{0}/{1}\".format(i, len(images)))\n",
    "        con_matrix -= torch.mm(self.mean.t(), self.mean)\n",
    "        # E: 固有値 V: 固有ベクトルを並べたもの\n",
    "        E, V = torch.linalg.eigh(con_matrix)  # 固有値分解\n",
    "        self.ZCA_matrix = torch.mm(torch.mm(V, torch.diag((E.squeeze()+self.epsilon)**(-0.5))), V.t())  # A(\\Lambda + \\epsilon I)^{1/2}A^T\n",
    "        print(\"completed!\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        size = x.size()\n",
    "        x = x.reshape(1, -1).to(self.device)\n",
    "        print(x.shape)\n",
    "        print(self.mean.shape)\n",
    "        x -= self.mean  # x - \\bar{x}\n",
    "        x = torch.mm(x, self.ZCA_matrix.t())\n",
    "        x = x.reshape(tuple(size))\n",
    "        x = x.to(\"cpu\")\n",
    "        return x\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        state = torch.load(filepath)\n",
    "        instance = cls(epsilon=state['epsilon'], device=state['device'])\n",
    "        instance.mean = state['mean']\n",
    "        instance.ZCA_matrix = state['ZCA_matrix']\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムデータセット\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_train, t_train, transform=None):\n",
    "        data = x_train.astype('float32')\n",
    "        # self.x_train = data\n",
    "        # data = np.transpose(x_train, (0, 2, 3, 1)).astype('float32')\n",
    "        self.x_train = []\n",
    "        if x_train.shape[3] == 3:\n",
    "            for i in range(data.shape[0]):\n",
    "                self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
    "        else:\n",
    "            for i in range(x_train.shape[0]):\n",
    "                # グレースケール画像を2D配列として扱う\n",
    "                img = x_train[i].squeeze()  # (28, 28, 1) -> (28, 28)\n",
    "                # 0-255の範囲にスケーリング（必要な場合）\n",
    "                # img = (img * 255).astype(np.uint8)\n",
    "                self.x_train.append(Image.fromarray(img, mode='L'))\n",
    "        self.t_train = t_train\n",
    "        if transform is None:\n",
    "            self.transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_train = self.transform(self.x_train[idx])\n",
    "        t_train = torch.tensor(self.t_train[idx], dtype=torch.long)\n",
    "\n",
    "        return x_train, t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化後の画像を[0, 1]に正規化する\n",
    "def deprocess(x):\n",
    "    \"\"\"\n",
    "    Argument\n",
    "    --------\n",
    "    x : np.ndarray\n",
    "        入力画像．(H, W, C)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    _x : np.ndarray\n",
    "        [0, 1]で正規化した画像．(H, W, C)\n",
    "    \"\"\"\n",
    "    _min = np.min(x)\n",
    "    _max = np.max(x)\n",
    "    _x = (x - _min)/(_max - _min)\n",
    "    return _x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムデータセット\n",
    "class PreDataset(Dataset):\n",
    "    def __init__(self, x_train, transform=None):\n",
    "        data = x_train.astype('float32')\n",
    "        # self.x_train = data\n",
    "        # data = np.transpose(x_train, (0, 2, 3, 1)).astype('float32')\n",
    "        self.x_train = []\n",
    "        if x_train.shape[3] == 3:\n",
    "            for i in range(data.shape[0]):\n",
    "                self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
    "        else:\n",
    "            for i in range(x_train.shape[0]):\n",
    "                # グレースケール画像を2D配列として扱う\n",
    "                img = x_train[i].squeeze()  # (28, 28, 1) -> (28, 28)\n",
    "                # 0-255の範囲にスケーリング（必要な場合）\n",
    "                # img = (img * 255).astype(np.uint8)\n",
    "                self.x_train.append(Image.fromarray(img, mode='L'))\n",
    "        if transform is None:\n",
    "            self.transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self.normal_transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        normal_x = self.normal_transform(self.x_train[idx])\n",
    "        pre_x = self.transform(self.x_train[idx])\n",
    "\n",
    "        return normal_x, pre_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukihito\\AppData\\Local\\Temp\\ipykernel_29468\\2424392530.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3072])\n",
      "torch.Size([1, 3072])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "(32, 32, 3)\n",
      "['iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAABOUlEQVRIDZ3BAbaiMADAwOT+h85WfKzwpVKdceAbcUFO4sWBNTElJ/HiwJ1YIg9x4sBcfBYPMufAm1gXyJwDB3FWzAjIHQd2cVbckp38Vzy5YRdnxToBGYoDBzbxpviOCMWBKDPFt5TiQJSZ4ltKcSDKpeIHSnEgyqUCVKDiV6JcKkAFKn4lyqUCVKDiV6JshDgoQGVX8T0H3sSmVHYVT8pQLHBgokJENhWgArErPvGBiYBS2QVyEgexC0QGByYCSmUTUCpX4ppDPMhfAaWyC+ST+EuUnZwElMoukBtxIogM8ldAISKbQO7FiyAiFyo2Kt+LB1G5FlCAyi6QVYEDEwEFqGwqQGVN4MBExUZlUzGoLAkcuBJQPIlYsVNZ48CVijmVNQ68CSg+UFniwJuKOyoLHHhTsUDlzj+Gq5VRPF4eZgAAAABJRU5ErkJggg==']\n",
      "['iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAABuklEQVRIDaXBAVYbVwBFMd39L/r1jzGhTjw0nEodnkae5ilfRpgXuTU6fBk5Rr4x8t9G5SH3Rl6MXEbem0t5KDfmkh+bS0kY+X/mki+jJB9GzCVPI0/bqpHvzCWXDp9G/rB5q/yFDt/YfCi/zDEL5a2Ro8M7I2zKsXmRy5R3Zgkd7m2rsK3alMvmYYX8boTpcGNTtlWYp4xG2FbIG9s63Bp52FZ5MSM08l6Hd4at8rAtFEaetlVGfjOXDje2VdhoaYTNw6h8q8M7w1ZhW4VtuaxyGc1TXszR4cvIp22VT6MNKxabyp1hHW5sq/wyMxUjRsMcIZeRy+jixrZCHrYV8i8jbORp5MjR4d62yqeRb438W4cbw1b5sI3KT3S4t63yaVvlJzo2l+R32yq/zHLkvZEXEUL+tK3ytE3lJyLJG8Om8jSj/IeRp6i8NdqW5NPID6RyaxsqRrZRMfIXOtwZNioftlH5C3Pp8NbMh1XYptpIPox8mRfR4Z1tlWObalPDsEJGbsylwzvbVMMmlG0xVB425dXIU4c/baNybBiVywzJyGWechlhWw8+jVy2oXJsWJmyLZdRjdwa/wAs/Qx/4b5a7gAAAABJRU5ErkJggg==']\n"
     ]
    }
   ],
   "source": [
    "# 前処理後の画像の取得\n",
    "def get_images(config):\n",
    "    project_name = config['project_name']\n",
    "    dataset_dir = os.path.abspath(os.path.join(os.getcwd(), \"../dataset\", project_name))\n",
    "    x_train = np.load(os.path.join(dataset_dir, \"x_train.npy\"))\n",
    "    image_shape = int(config['input_info']['change_shape'])\n",
    "    preprocessing = config['input_info']['preprocessing']\n",
    "    transform_list = [\n",
    "        transforms.Resize((image_shape, image_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "    if preprocessing == 'GCN':\n",
    "        gcn = GCN()\n",
    "        transform_list.append(gcn)\n",
    "    elif preprocessing == 'ZCA':\n",
    "        zca = ZCAWhitening.load(os.path.join(dataset_dir, f\"{project_name}_zca.pth\"))\n",
    "        transform_list.append(zca)\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    train_dataset = PreDataset(x_train, transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=int(1), shuffle=True)\n",
    "    i = 0\n",
    "    images = []\n",
    "    pre_images = []\n",
    "    for x, pre in train_loader:\n",
    "        print(x.shape)\n",
    "        numpy_x = x.numpy()\n",
    "        numpy_x = np.transpose(numpy_x[0], (1, 2, 0))\n",
    "        numpy_pre = pre.numpy()\n",
    "        numpy_pre = np.transpose(numpy_pre[0], (1, 2, 0))\n",
    "        cv2.imshow('normal', numpy_x)\n",
    "        cv2.imshow('preprocessing', deprocess(numpy_pre))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(numpy_x.shape)\n",
    "        _, img_png = cv2.imencode('.png', numpy_x)\n",
    "        img_base64 = base64.b64encode(img_png).decode()\n",
    "        images.append(img_base64)\n",
    "        _, pre_img_png = cv2.imencode('.png', deprocess(numpy_pre))\n",
    "        pre_img_base64 = base64.b64encode(pre_img_png).decode()\n",
    "        pre_images.append(pre_img_base64)\n",
    "        i += 1\n",
    "        if i == 1:\n",
    "            break\n",
    "    print(images)\n",
    "    print(pre_images)\n",
    "\n",
    "\n",
    "config = {\n",
    "    'project_name': 'CIFAR10',\n",
    "    'input_info': {\n",
    "        'change_shape': '32',\n",
    "        'preprocessing': 'ZCA'\n",
    "    }\n",
    "}\n",
    "get_images(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispend_image(self):\n",
    "    #\n",
    "    # バイナリコードにする\n",
    "    # ------------------------------\n",
    "    # description :\n",
    "    #   画像データをpng -> base64に変換して返す\n",
    "    # argmetns :\n",
    "    #   * __init__にて定義\n",
    "    # return :\n",
    "    #   画像データ（base64）(list)\n",
    "    images = []\n",
    "    for img in self.x:\n",
    "        if self.config['color'] == 'gray': # グレースケール(チャンネル１)\n",
    "            img = img.reshape(self.config['shape'])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) # グレースケールを3chに変換\n",
    "            _, img_png = cv2.imencode('.png', img)\n",
    "            img_base64 = base64.b64encode(img_png).decode()\n",
    "            images.append(img_base64)\n",
    "        if self.config['color'] == 'rgb': # カラー(チャンネル３) * 検証まだ\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            _, img_png = cv2.imencode('.png', img)\n",
    "            img_base64 = base64.b64encode(img_png).decode()\n",
    "            images.append(img_base64)\n",
    "    return images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
